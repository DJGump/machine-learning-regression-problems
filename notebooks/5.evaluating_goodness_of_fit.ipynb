{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Goodness of Fit of Linear Regression Models\n",
    "\n",
    "So far, we've learned how to build a linear regression model and interpret the estimated coefficients. In this checkpoint, we discuss how we evaluate the performance of our models in the training phase. Recall that we can talk about two broad types of performances: one in the training set and the other in the test set. The former enables us to talk about how well our model explains the information in the target variable and the later gives us an idea about how well our model will perform when it's given previously unseen observations.\n",
    "\n",
    "First, we start with the investigation of whether an estimated model deems better than a reduced model. By reduced model, we mean a model with no features. To compare our model with the reduced model, we use **F-test**.\n",
    "\n",
    "Second, we delve into the measurement of how well our model explains the variance in the target variable. To this end, we talk about **R-squared** and **adjusted R-squared**.\n",
    "\n",
    "Last, we explain how we can compare different models in terms of their explanatory power. We show how to read **Akaike** and **Bayesian** information criterias for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is our model better than an \"empty\" model?\n",
    "\n",
    "When evaluating our model, we first need to ask whether our model contributes anything to the explanation of the outcome variable. In other words, we need to determine whether our features are any useful in explaining the variance of the outcome. If not, we can drop our features altogether and the resulting \"empty\" model would do the same job.\n",
    "\n",
    "For this purpose, we use **F-test**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The F-test\n",
    "\n",
    "The F-test can be calculated in different ways depending on the situation, but principally represents the ratio between the unexplained variance of our model and the unexplained variance of a reduced model to which our model is compared.  Here, the \"reduced model\" is a model with no features, meaning all variance in the outcome is unexplained.  For a linear regression model with two parameters $y=\\alpha+\\beta x$, the F-test is built from these pieces:\n",
    "\n",
    "* unexplained model variance:\n",
    "\n",
    "$$SSE_F=\\sum(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "* unexplained variance in reduced model:\n",
    "\n",
    "$$SSE_R=Var_y = \\sum(y_i-\\bar{y})^2$$\n",
    "\n",
    " * number of parameters in the model:\n",
    "\n",
    "$$p_F = 2 (\\alpha \\text{ and } \\beta)$$\n",
    "\n",
    " * number of parameters in the reduced model:\n",
    "\n",
    "$$p_R = 1 (\\alpha)$$\n",
    "\n",
    " * number of datapoints:\n",
    "\n",
    "$$n$$\n",
    "\n",
    " * degrees of freedom of $SSE_F$:\n",
    "\n",
    "$$df_F = n - p_F$$\n",
    "\n",
    " * degrees of freedom of $SSE_R$:\n",
    "\n",
    "$$df_R = n - p_R$$\n",
    "\n",
    "These pieces come together to give us the full equation for the F-test:\n",
    "\n",
    "$$F=\\dfrac{SSE_F-SSE_R}{df_F-df_R}รท\\dfrac{SSE_F}{df_F}$$\n",
    "\n",
    "This introduces some new terminology. **Degrees of freedom** quantify the amount of information \"left over\" to estimate variability after all parameters are estimated.\n",
    "\n",
    "In regression, degrees of freedom for a function works like this:  With two datapoints, a regression line $y=\\alpha + \\beta x$ has 0 degrees of freedom (2 minus the number of parameters).  Those two parameters encompass all the information in the data.  Knowing $\\alpha$ and $\\beta$ alone, we can perfectly reproduce the original data.  No additional information is available from the data itself.\n",
    "\n",
    "The null hypotheses of the F-test states that the model is indifferent from the reduced model which means that the features contributes nothing to the explanation of the target variable. Instead of reading the F statistics, it's easier to read the p-value of it. The lesser the p-value, the better for our model. Namely, if the p-value of the F test for our model is less than or equal to 0.1 (or even less than or equal to 0.05), we say that our model is useful and contributes something that is statistically significant in the explanation of the target.\n",
    "\n",
    "Let's see the F statistic of our medical costs model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>25.740</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>3756.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46</td>\n",
       "      <td>female</td>\n",
       "      <td>33.440</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>8240.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>female</td>\n",
       "      <td>27.740</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>7281.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "      <td>29.830</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>6406.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>female</td>\n",
       "      <td>25.840</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>28923.137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    bmi  children smoker     region   charges\n",
       "0   19  female 27.900         0    yes  southwest 16884.924\n",
       "1   18    male 33.770         1     no  southeast  1725.552\n",
       "2   28    male 33.000         3     no  southeast  4449.462\n",
       "3   33    male 22.705         0     no  northwest 21984.471\n",
       "4   32    male 28.880         0     no  northwest  3866.855\n",
       "5   31  female 25.740         0     no  southeast  3756.622\n",
       "6   46  female 33.440         1     no  southeast  8240.590\n",
       "7   37  female 27.740         3     no  northwest  7281.506\n",
       "8   37    male 29.830         2     no  northeast  6406.411\n",
       "9   60  female 25.840         0     no  northwest 28923.137"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('postgresql://username:pass@localhost:5432/MedicalCosts')\n",
    "\n",
    "insurance_df = pd.read_sql_query('select * from medicalcosts',con=engine)\n",
    "insurance_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df[\"is_male\"] = pd.get_dummies(insurance_df.sex, drop_first=True)\n",
    "insurance_df[\"is_smoker\"] = pd.get_dummies(insurance_df.smoker, drop_first=True)\n",
    "\n",
    "insurance_df.region[np.where(np.isin(insurance_df.region, \"southwest\"))[0]] = 0\n",
    "insurance_df.region[np.where(np.isin(insurance_df.region, \"northwest\"))[0]] = 1\n",
    "insurance_df.region[np.where(np.isin(insurance_df.region, \"southeast\"))[0]] = 2\n",
    "insurance_df.region[np.where(np.isin(insurance_df.region, \"northeast\"))[0]] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                charges   R-squared:                       0.747\n",
      "Model:                            OLS   Adj. R-squared:                  0.747\n",
      "Method:                 Least Squares   F-statistic:                     986.5\n",
      "Date:                Thu, 18 Oct 2018   Prob (F-statistic):               0.00\n",
      "Time:                        17:22:21   Log-Likelihood:                -13557.\n",
      "No. Observations:                1338   AIC:                         2.712e+04\n",
      "Df Residuals:                    1333   BIC:                         2.715e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -1.163e+04    947.267    -12.281      0.000   -1.35e+04   -9775.198\n",
      "is_male     -109.0411    334.665     -0.326      0.745    -765.568     547.486\n",
      "is_smoker   2.383e+04    414.186     57.544      0.000     2.3e+04    2.46e+04\n",
      "age          259.4532     11.942     21.727      0.000     236.027     282.880\n",
      "bmi          323.0511     27.529     11.735      0.000     269.046     377.056\n",
      "==============================================================================\n",
      "Omnibus:                      299.394   Durbin-Watson:                   2.076\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              708.639\n",
      "Skew:                           1.212   Prob(JB):                    1.32e-154\n",
      "Kurtosis:                       5.614   Cond. No.                         292.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Y is the target variable\n",
    "Y = insurance_df['charges']\n",
    "\n",
    "# X is the feature set\n",
    "X = insurance_df[['is_male','is_smoker', 'age', 'bmi']]\n",
    "\n",
    "# We add constant to the model as it's a best practice\n",
    "# to do so everytime!\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# We fit an OLS model using statsmodels\n",
    "results = sm.OLS(Y, X).fit()\n",
    "\n",
    "# We print the summary results.\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model's F statistic is 986.5 and the associated p-value is very close to zero. This means that, our features add some information to the reduced model and our model is useful for explaning the charges.\n",
    "\n",
    "However, F-test doesn't provide us a measure to quantify how much information our model contributes. To this purpose, we discuss the R-squared next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying the performance of a model in the training set\n",
    "\n",
    "R-squared is probably the most common measure of goodness of fit in a linear regression model. It is a proportion (between 0 and 1) that expresses how much variance in the outcome variable is explained by the explanatory variables in the model. Generally speaking, higher $R^2$ values are better to a point-- a low $R^2$ indicates that our model isn't explaining much information about the outcome, which means it will not give very good predictions. However, a very high $R^2$ is a warning sign for overfitting.  No dataset is a perfect representation of reality, so a model that perfectly fits our data ($R^2$ of 1 or close to 1) is likely to be biased by quirks in the data, and will perform less well on the test-set.\n",
    "\n",
    "In the regression summary table above, we see that the R-squared value of our medical costs model is 0,747. It means that our model explains 74,7% of the variance in the charges. So, 25,3% is still unexplained. Hence, we can conclude that there are still room for improvement. Let's fit the model in the previous checkpoint again where we included the interaction of body mass index (bmi) and is_smoking dummy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                charges   R-squared:                       0.837\n",
      "Model:                            OLS   Adj. R-squared:                  0.836\n",
      "Method:                 Least Squares   F-statistic:                     1365.\n",
      "Date:                Thu, 18 Oct 2018   Prob (F-statistic):               0.00\n",
      "Time:                        18:11:24   Log-Likelihood:                -13265.\n",
      "No. Observations:                1338   AIC:                         2.654e+04\n",
      "Df Residuals:                    1332   BIC:                         2.657e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const         -2071.0773    840.644     -2.464      0.014   -3720.208    -421.946\n",
      "is_male        -473.4951    269.612     -1.756      0.079   -1002.406      55.415\n",
      "is_smoker     -2.019e+04   1666.491    -12.117      0.000   -2.35e+04   -1.69e+04\n",
      "age             266.3723      9.612     27.713      0.000     247.516     285.228\n",
      "bmi               7.9686     25.044      0.318      0.750     -41.160      57.098\n",
      "bmi_is_smoker  1435.6081     53.242     26.964      0.000    1331.160    1540.056\n",
      "==============================================================================\n",
      "Omnibus:                      710.004   Durbin-Watson:                   2.059\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4260.528\n",
      "Skew:                           2.491   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.183   Cond. No.                         661.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Y is the target variable\n",
    "Y = insurance_df['charges']\n",
    "\n",
    "# This is the interaction between bmi and smoking\n",
    "insurance_df[\"bmi_is_smoker\"] = insurance_df.bmi * insurance_df.is_smoker\n",
    "\n",
    "# X is the feature set\n",
    "X = insurance_df[['is_male','is_smoker', 'age', 'bmi', \"bmi_is_smoker\"]]\n",
    "\n",
    "# We add constant to the model as it's a best practice\n",
    "# to do so everytime!\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# We fit an OLS model using statsmodels\n",
    "results = sm.OLS(Y, X).fit()\n",
    "\n",
    "# We print the summary results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared of this model is 0,837 which is higher than our previous model's. This improvement indicates that the interactions of bmi and is_smoker explains some previously unexplained variance of the charges. \n",
    "\n",
    "As we said before, high R-squared values are generally something admirable. However, in some cases, very high R-squared values indicate some potential problems with our model. Specifically:\n",
    "\n",
    "* Very high R-squared value may be a sign of overfitting. If our model is too complex for the data, then it may overfit the training set and does a poor job in the test set. **To assess this, we need to evaluate the performance of our model in the test set and see whether our model does a significantly poor job in the test set compared to the training set**. We'll discuss how to evaluate liear regression models in the test set in the next checkpoint.\n",
    "\n",
    "* R-squared is inherently a biased estimate of the performance in the sense that the more explanatory variables are added to the model, the higher R-squared values we get. This is so even we include irrelevant variables like noises or random data. To mitigate this problem, we usually use a metric called **adjusted R-squared** instead of R-squared. Adjusted R-squared does the same job with the R-squared but it is adjusted according to the number of features included to the model. Hence, it's always safer to look at the adjusted R-squared value instead of R-squared value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different models\n",
    "\n",
    "Comparing different models and chosing the best one is one of the essential practices in Data Science. Often, we try several models and evaluate them in the test set in order to detect the top performing one. However, *inference* is also a very critical task when it comes to linear regression models. Unlike testing the predictive power, in inference, we care about the explanatory power of our models.\n",
    "\n",
    "Throughout this checkpoint, we saw that we can measure the performance of our models in the training set using F-test or R-squared. Hence, both F-test and R-squared can be used in the comparison of different models. Unfortunately, the two metrics suffer from some drawbacks which make them inappropriate to use in some situations when comparing different models.\n",
    "\n",
    "Here we briefly overview how we can use F-test and R-squared in model comparison. Then, we introduce information criterions that we can also use to compare different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using F-test for model comparison\n",
    "\n",
    "We can use F-test to compare two models if one of them is nested within the other. That is, if the feature set in a model is a subset of the feature set of the other, then we can use F-test. In this case, we say that the model with higher F statistics is superior to the other one.\n",
    "\n",
    "However, if models are not nested, then using F-test might be misleading. It's quite sensitive to the normality of the error terms. If errors are not normally distributed, we should try other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using R-squared for model comparision\n",
    "\n",
    "Another metric we can use for model comparison is the R-squared. We already saw that R-squared is biased as it tends to increase with the number of explanatory variables. So, instead of R-squared we can use adjusted R-squared. The higher adjusted R-squared, the better model explains the target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using information criterions\n",
    "\n",
    "Using information criterions is also a common way of comparing different models and selecting the best one. Here, we talk about two information criterias known as **Akaike Information Criteria (AIC)** and **Bayesian Information Criterian (BIC)**. Both of these information criterias take into consideration the sum of the squared errors (SSE), the sample size and the number of parameters.\n",
    "\n",
    "The formula for AIC is:\n",
    "\n",
    "$$nln(SSE)โnln(n)+2p$$ \n",
    "\n",
    "\n",
    "and the formula for BIC is:\n",
    "\n",
    "$$nln(SSE)โnln(n)+pln(n)$$\n",
    "\n",
    "In both of these formulas, $n$ represents the sample size and $p$ represents the number of regression coefficients in the model (including the constant).\n",
    "\n",
    "For both of AIC and BIC, the lower value the better. Hence, we choose the model with the lowest AIC or BIC value. Although, we can use ony one of the two criterias, AIC is usually criticized for its tendency to overfit. In contrast, BIC penalizes the number of parameters more severely than AIC and hence favors more parsimonious (models with lesser number of parameters) models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which medical costs model is better?\n",
    "\n",
    "statmodels' `summary()` function gives us all of the above metrics. In the tables above, we see that for our first model, R-squared is 0.747, adjusted R-squared is 0.747, F statistics is 986.5, AIC is 27.120 and BIC is 27.150 whereas for our second model, R-squared is 0.837, adjusted R-squared is 0.836, F statistics is 1365, AIC is 26.540 and BIC is 26.570. According to all of the metrics, our second model seems better than the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Using your house prices model:\n",
    "\n",
    "* Assess the goodness of fit of your model using F-test, R-squared, adjusted R-squared, AIC and BIC.\n",
    "* Do you think your model is satisfactory? If so, why?\n",
    "* In order to improve the goodness of fit of your model, try different model specifications by adding and removing some variables. \n",
    "* For each model you try, get the goodness of fit metrics and compare your models with each other. Which model is the best and why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
